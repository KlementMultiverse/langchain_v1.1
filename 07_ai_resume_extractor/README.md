# AI Resume Extractor

**Extract structured data from resumes using AI (LangChain + Pydantic + Ollama)**

## What This Does

Takes messy resume files (PDF, DOCX, TXT) and extracts clean, structured data:
- Contact info (name, email, phone, location)
- Skills
- Work experience
- Education

**Input:** Resume file (any format)
**Output:** Clean JSON data ready for database

---

## The Plan (What We're Building)

```
User drops resumes â†’ source_folder/
â†“
Run program (python main.py)
â†“
AI extracts structured data
â†“
Saves to SQLite database
â†“
Deletes processed files
â†“
User can query/export from database
```

---

## Project Structure

```
07_ai_resume_extractor/
â”œâ”€â”€ models.py           âœ… DONE - Data structure (Pydantic models)
â”œâ”€â”€ file_loader.py      ğŸ”œ TODO - Load PDF/DOCX/TXT files
â”œâ”€â”€ config.py           ğŸ”œ TODO - Settings and prompts
â”œâ”€â”€ parser.py           ğŸ”œ TODO - AI extraction logic
â”œâ”€â”€ database.py         ğŸ”œ TODO - SQLite operations
â”œâ”€â”€ main.py             ğŸ”œ TODO - Main program
â”œâ”€â”€ reset_db.py         ğŸ”œ TODO - Reset database utility
â”œâ”€â”€ source_folder/      ğŸ“ Drop resumes here
â”œâ”€â”€ output/             ğŸ“ Exported files go here
â””â”€â”€ README.md           ğŸ“„ This file
```

---

## What We've Built So Far

### âœ… models.py (Completed)

**4 Pydantic Models:**

**1. ContactInfo**
```python
- name: str (required)
- email: str (required)
- phone: str (required) - 10 digits, no formatting
- location: str (optional) - City only
```

**2. JobExperience**
```python
- company: str
- title: str
- duration: str
- responsibilities: List[str]
```

**3. Education**
```python
- institution: str
- degree: str
- field: str (optional)
- year: str (optional)
```

**4. Resume (Main Model)**
```python
- contact: ContactInfo
- summary: str (optional)
- skills: List[str]
- experience: List[JobExperience]
- education: List[Education]
```

**Why Pydantic?**
- Validates data automatically
- Type safety (ensures email is string, phone is 10 digits, etc.)
- Easy conversion to JSON for database

**Example:**
```python
from models import Resume, ContactInfo, JobExperience, Education

resume = Resume(
    contact=ContactInfo(
        name="Sarah Martinez",
        email="sarah@email.com",
        phone="5557890123",
        location="Austin"
    ),
    skills=["Python", "SQL", "Tableau"],
    experience=[
        JobExperience(
            company="TechFlow",
            title="Product Manager",
            duration="2021-Present",
            responsibilities=["Led team of 10", "Launched $6M product"]
        )
    ],
    education=[
        Education(
            institution="UT Austin",
            degree="MBA",
            year="2019"
        )
    ]
)

# Convert to JSON for database
resume_json = resume.model_dump()
```

---

## Tech Stack

- **Python**: 3.10+
- **LangChain**: 1.2.0+ (AI orchestration)
- **Pydantic**: 2.10+ (data validation)
- **Ollama**: Local LLM (qwen3:4b model)
- **Document Loaders**: pypdf, python-docx, unstructured
- **Database**: SQLite (built-in)

---

## Installation

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Verify Ollama is running
ollama list  # Should show qwen3:4b
```

---

## Current Status

**Completed:**
- âœ… Project structure setup
- âœ… Dependencies installed
- âœ… Data models defined (models.py)
- âœ… Unit tests passed (all 10 tests)
- âœ… Sample resumes collected (PDF, DOCX, TXT)

**Next Steps:**
- ğŸ”œ Build file_loader.py (load PDF/DOCX/TXT)
- ğŸ”œ Build config.py (settings)
- ğŸ”œ Build parser.py (AI extraction)
- ğŸ”œ Build database.py (storage)
- ğŸ”œ Build main.py (orchestrator)

---

## Learning Concepts

**Day 7 Concepts Applied:**
1. **Pydantic BaseModel** - Data validation
2. **Field descriptions** - Guide AI extraction
3. **Optional vs Required** - Mandatory vs optional fields
4. **Nested models** - Models inside models (Resume contains JobExperience)
5. **Type hints** - str, int, List[str], Optional[str]

**Production Patterns:**
- Separation of concerns (each file has one job)
- Type safety (Pydantic validation)
- Modular architecture (reusable components)
- Unit testing (verify code works)

---

## Author

**Klement**
Learning LangChain 1.0 - Building production-grade AI systems
Date: December 15, 2025

---

## Notes

- USA resumes only (phone format: 10-digit US numbers)
- Location: City name only, no state
- Phone: Clean digits only, extensions removed
- All data validated before storage
- Designed for real-world resume parsing scenarios
