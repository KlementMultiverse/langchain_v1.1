# ğŸ™ï¸ Real-time Personal AI Assistant

**Day 8 - Program 4: Streaming + Callbacks + Real-time Audio**

A voice assistant that responds in **0.3-0.5 seconds** using LangChain streaming, custom callbacks, and VibeVoice TTS.

---

## ğŸ¯ What This Demonstrates

### **LangChain Concepts:**
1. **Streaming** (Day 8 Program 1) - Token-by-token output
2. **Custom Callbacks** (Day 8 Program 2) - Real-time sentence detection
3. **LCEL Chains** (Day 3) - Composable LangChain pipelines
4. **Production Architecture** - Multi-file, modular design

### **Advanced Patterns:**
- Queue-based threading for concurrent text/audio processing
- Sentence-boundary detection during streaming
- Real-time TTS generation (~300ms latency)
- Groq API integration (500+ tokens/sec)

---

## ğŸ—ï¸ Architecture

```
User Question
     â†“
Groq LLM (Streaming)  â† LangChain Chain
     â†“
SentenceDetectorCallback  â† Custom Callback
     â†“
Audio Queue  â† Thread-safe FIFO
     â†“
VibeVoice TTS  â† Audio Thread
     â†“
Speakers ğŸ”Š
```

**Result:** Audio plays AS text streams in!

---

## ğŸ“‚ Project Structure

```
08_realtime_assistant/
â”œâ”€â”€ config.py              # Settings, API keys, prompts
â”œâ”€â”€ callbacks.py           # LangChain custom callbacks
â”œâ”€â”€ audio_engine.py        # VibeVoice TTS integration
â”œâ”€â”€ chain.py               # LangChain streaming chain
â”œâ”€â”€ main.py                # Main orchestrator
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ .env                   # API keys (not in git)
â”œâ”€â”€ .gitignore             # Protect secrets
â””â”€â”€ README.md              # This file
```

---

## âš¡ Speed Breakdown

| Event | Time | What Happens |
|-------|------|--------------|
| **0.00s** | User presses Enter | Question sent to Groq |
| **0.05s** | First token arrives | Text starts appearing |
| **0.15s** | 4 words received | "Machine learning is a" |
| **0.30s** | **ğŸ”Š AUDIO STARTS** | User hears first words! |
| **0.50s** | Next chunk | Continuous speech |

**Total latency: 0.3-0.5 seconds!** âš¡

---

## ğŸš€ Setup

### **1. Install Dependencies**

```bash
# Install LangChain + Groq
pip install langchain-core langchain-groq python-dotenv

# Install VibeVoice (if not already installed)
cd /tmp
git clone https://github.com/microsoft/VibeVoice.git
cd VibeVoice
pip install -e .
```

### **2. Set Up API Key**

Create `.env` file:
```bash
GROQ_API_KEY=your_groq_api_key_here
```

Get free Groq API key: https://console.groq.com/

### **3. Download Models**

Models download automatically on first run:
- VibeVoice-Realtime-0.5B (2GB)
- Already downloaded to HuggingFace cache

---

## ğŸ® Usage

```bash
# Run the assistant
python main.py
```

**Example Session:**
```
ğŸ¤” You: What is machine learning?

ğŸ™ï¸  Assistant speaking...
ğŸ’¬ Assistant: Machine learning is a type of artificial intelligence that enables
computers to learn from data without being explicitly programmed. It uses
algorithms to identify patterns and make predictions or decisions.

âœ… Assistant finished speaking

ğŸ“Š Metrics:
   Tokens: 45
   Duration: 2.3s
   Speed: 495.7 tokens/sec
```

---

## ğŸ§  How It Works

### **Step 1: User Asks Question**
```python
question = "What is machine learning?"
```

### **Step 2: Groq Streams Response**
```python
chain.stream(question, callbacks=[sentence_callback])
```
- Groq generates tokens at 500+/sec
- Tokens arrive one at a time

### **Step 3: Callback Detects Sentences**
```python
class SentenceDetectorCallback(BaseCallbackHandler):
    def on_llm_new_token(self, token: str, **kwargs):
        # Buffer tokens
        self.buffer += token

        # Detect sentence end
        if token in ['.', '!', '?']:
            audio_queue.put(self.buffer)
```

### **Step 4: Audio Thread Processes Queue**
```python
while True:
    chunk = audio_queue.get()  # Blocks until available
    audio = vibevoice.synthesize(chunk)  # 300ms
    vibevoice.play(audio)  # Immediate playback
```

### **Step 5: User Hears Response**
- First audio chunk plays at 0.3s
- Continuous speech with no gaps
- Natural conversational flow

---

## ğŸ“ Key Learnings

### **1. LangChain Streaming**
```python
for chunk in chain.stream(question):
    print(chunk, end="", flush=True)
```
- Tokens appear immediately
- Better UX than waiting for full response

### **2. Custom Callbacks**
```python
class SentenceDetectorCallback(BaseCallbackHandler):
    def on_llm_start(...): pass
    def on_llm_new_token(...): pass  # Called per token!
    def on_llm_end(...): pass
```
- Foundation of observability tools
- Enables real-time processing

### **3. Queue-based Threading**
```python
audio_queue = queue.Queue()  # Thread-safe FIFO
audio_queue.put(chunk)       # Producer
chunk = audio_queue.get()    # Consumer (blocks)
```
- Decouples text streaming from audio generation
- Ensures smooth playback

### **4. Sentence Detection**
```python
if word_count >= 4 or token in ['.', '!', '?', ',']:
    audio_queue.put(buffer)
```
- Don't wait for full sentences
- Send mini-chunks (3-4 words)
- Creates "real-time" feel

---

## ğŸ”§ Configuration

Edit `config.py` to customize:

```python
# Model settings
MODEL_NAME = "llama-3.3-70b-versatile"  # Groq model
TEMPERATURE = 0.7

# Audio settings
MIN_CHUNK_WORDS = 4    # Smaller = faster audio
MAX_CHUNK_WORDS = 15   # Larger = more natural

# Assistant personality
ASSISTANT_PROMPT = "You are a helpful assistant..."
```

---

## ğŸ“Š Performance

### **Hardware Requirements:**
- **GPU:** NVIDIA GPU with 2.5GB+ VRAM (for VibeVoice)
- **RAM:** 4GB+ recommended
- **Internet:** Stable connection (for Groq API)

### **Latency Breakdown:**
- Groq first token: 50-100ms
- Sentence detection: <1ms
- VibeVoice synthesis: 200-300ms
- **Total:** 300-500ms âš¡

### **Comparison:**
| System | First Response | Feel |
|--------|---------------|------|
| **This Assistant** | 0.3-0.5s | âš¡ Instant |
| ChatGPT Voice | 1-2s | Good |
| Traditional Bot | 10-15s | ğŸ˜´ Slow |

---

## ğŸ¯ Production Enhancements

### **Future Improvements:**
1. **Memory:** Add conversation history (Day 5)
2. **Tools:** Enable function calling (Day 4)
3. **RAG:** Connect to knowledge base (Day 6)
4. **Multi-speaker:** Add voice selection
5. **Streaming Audio:** Stream TTS output (even faster!)

---

## ğŸ› Troubleshooting

### **Issue: "GROQ_API_KEY not found"**
```bash
# Create .env file with your API key
echo "GROQ_API_KEY=your_key_here" > .env
```

### **Issue: "CUDA out of memory"**
```python
# In config.py, switch to CPU:
VIBEVOICE_DEVICE = "cpu"
```
Note: CPU is slower (~1-2s latency)

### **Issue: "VibeVoice module not found"**
```bash
cd /tmp/VibeVoice
pip install -e .
```

---

## ğŸ“š Related Programs

**Day 8 Series:**
1. `08_01_basic_streaming.py` - Streaming basics
2. `08_02_callback_handlers.py` - Custom callbacks
3. `08_03_cost_tracking.py` - Token/cost tracking
4. **`08_realtime_assistant/`** - This program! ğŸ™ï¸

---

## ğŸ“ Learning Path

**You've now mastered:**
âœ… LLM streaming (Day 8.1)
âœ… Custom callbacks (Day 8.2)
âœ… Cost tracking (Day 8.3)
âœ… **Real-time audio integration (Day 8.4)** â† You are here!

**Next steps:**
- Day 9: Advanced RAG patterns
- Day 10: Agentic workflows
- Production deployment

---

## ğŸ“ Notes

- This uses local TTS (VibeVoice) - no cloud latency!
- Groq free tier: 30 requests/min, 6000 tokens/min
- Models cached in `~/.cache/huggingface/`

---

**Built with:**
- LangChain 1.2.0+
- Groq API (Llama 3.3 70B)
- VibeVoice-Realtime-0.5B
- Python 3.12+
- PyTorch 2.0+

---

ğŸ‰ **Congratulations!** You've built a production-quality real-time voice assistant using pure LangChain patterns!
